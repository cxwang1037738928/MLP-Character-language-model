{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# reads in all the words\n",
    "words = open(\"names.txt\", 'r').read().splitlines()\n",
    "\n",
    "# building encoder\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s, i in stoi.items()}\n",
    "\n",
    "# set parameters\n",
    "n_hidden = 200\n",
    "n_embd = 10\n",
    "numb_tests = 10000\n",
    "block_size = 10 # context, number of characters taken in to predict the next\n",
    "vocab_size = len(itos)\n",
    "\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "C = torch.randn((vocab_size, n_embd), generator=g) # embed table, 27 rows for 27 characters, crammed into a two dimensional space(each character has a 2d embedding)\n",
    "W1 = torch.randn((block_size*n_embd, n_hidden), generator=g)*(5/3)/((block_size*n_embd)**0.5)  # kaiming init for non-linear\n",
    "#b1 = torch.randn(n_hidden, generator=g) * 0.01 wiped out by batch normalization's (hpreact - bnmeani)\n",
    "W2 = torch.randn((n_hidden, vocab_size), generator=g)*0.01 #output is number of characters, made smaller to minimize logits on first iteration\n",
    "b2 = torch.randn(vocab_size, generator=g) * 0 # makes biases all 0 and equal at initialization\n",
    "\n",
    "# parameters of batch normalization\n",
    "bngain = torch.ones((1, n_hidden))\n",
    "bnbias = torch.zeros((1, n_hidden)) # replaces b1\n",
    "\n",
    "# buffers of batch normalization\n",
    "bnmean_running = torch.zeros((1, n_hidden))\n",
    "bnstd_running = torch.ones((1, n_hidden))\n",
    "\n",
    "parameters = [C, W2, b2, W1, bngain, bnbias]\n",
    "for p in parameters:\n",
    "    p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2023)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = 0.2\n",
    "(torch.randn(10000)*std).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words):\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        context = [0] * block_size # padding with [0] = '.'\n",
    "        for ch in w + '.':\n",
    "            ix = stoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix) \n",
    "            context = context[1:] + [ix]\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    return X, Y\n",
    " # training split, dev/validation split, test split\n",
    " # 80%, 10%, 10%\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "Xtr, Ytr = build_dataset(words[:n1])\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])\n",
    "Xte, Yte = build_dataset(words[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = C[Xtr]\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenates the vectors\n",
    "hpreact = embcat @ W1  # hidden layer pre-activation, note that since the equation of self_grad of a neuron is proportional to (1-hpreact**2), this can only ever decrease, and\n",
    "                           # approaches zero whenever t approaches abs(1) \n",
    "h = torch.tanh(hpreact) # activation of hidden states/hidden layer\n",
    "logits = h @ W2 + b2 \n",
    "loss = F.cross_entropy(logits, Ytr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "stepi = []\n",
    "batch_size = 32\n",
    "# backward pass\n",
    "for i in range(numb_tests):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size, )) # list of 32 integers that index into the data, e.g their range is between 0 and number of data inputs,\n",
    "    \n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xtr[ix]] # shape = (X.shape[0], block_size, n_hidden)\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    \n",
    "    hpreact = embcat @ W1 #+ b1\n",
    "    bnmeani = hpreact.mean(0, keepdim=True)\n",
    "    bnstdi = hpreact.std(0, keepdim=True)\n",
    "    hpreact = bngain * (hpreact - bnmeani) / bnstdi + bnbias # bngain and bnbias will be 1 and 0 at init, but will be changed by back prop\n",
    "\n",
    "    # updates batch mean and std as its running\n",
    "    with torch.no_grad():\n",
    "        bnmean_running = 0.999 * bnmean_running + 0.001 * bnmeani\n",
    "        bnstd_running = 0.999 * bnstd_running + 0.001 * bnstdi\n",
    "\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Ytr[ix]) # loss function\n",
    "    \n",
    "    for p in parameters:\n",
    "        p.grad = None\n",
    "\n",
    "    loss.backward() # updates gradients for each neuron\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < (numb_tests/2) else 0.01\n",
    "    for p in parameters:\n",
    "        p.data += -lr * p.grad # adjust data according to gradient\n",
    "    lossi.append(loss.item())\n",
    "    stepi.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x253b32953d0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.imshow(h.abs() > 0.99, cmap='gray', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate the batch norm at the end of training\n",
    "\n",
    "# with torch.no_grad(): # Does not keep track of grad for this function\n",
    "#     # pass the training set through\n",
    "#     emb = C[Xtr]\n",
    "#     embcat = emb.view(emb.shape[0], -1)\n",
    "#     hpreact = embcat @ W1 + b1\n",
    "#     # measure the mean/std over the entire training set, now mean/std are fixed tensors, makes sampling easier now that we don't need batch_size number of inputs to estimate h\n",
    "#     bnmean = hpreact.mean(0, keepdim=True)\n",
    "#     bnstd = hpreact.std(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.068458318710327\n",
      "val 2.1092183589935303\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad() # decorator to disable gradient tracking for all tensors in this function\n",
    "def split_loss(split):\n",
    "    x, y = {\n",
    "        'train': (Xtr, Ytr),\n",
    "        'val': (Xdev, Ydev),\n",
    "        'test': (Xte, Yte)\n",
    "    }[split]\n",
    "    emb = C[x] # (N, block_size, n_embd)\n",
    "    embcat = emb.view(emb.shape[0], -1)\n",
    "    hpreact = embcat @ W1 #+ b1 # linear layer\n",
    "    hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias # now function of all examples in the batch, noise regularizes neural net\n",
    "    h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "    logits = h @ W2 + b2 # (N, vocab_size)\n",
    "    loss = F.cross_entropy(logits, y)\n",
    "    print(split, loss.item())\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caillianord.\n",
      "kenie.\n",
      "veouh.\n",
      "ild.\n",
      "makehlie.\n",
      "grishemileigh.\n",
      "brodessam.\n",
      "maleck.\n",
      "arril.\n",
      "jakyorette.\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    out = []\n",
    "    context = [0] * block_size\n",
    "    while True:\n",
    "        emb = C[torch.tensor([context])] # (1, block_size, d)\n",
    "        embcat = emb.view(1, -1)\n",
    "        hpreact = embcat @ W1\n",
    "        hpreact = bngain * (hpreact - bnmean_running) / bnstd_running + bnbias\n",
    "        h = torch.tanh(hpreact)\n",
    "        logits = h @ W2 + b2\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(itos[i] for i in out))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
